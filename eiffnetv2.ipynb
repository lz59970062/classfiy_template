{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":[" "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Let us start by importing the libraries:"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2022-08-07T05:04:40.607083Z","iopub.status.busy":"2022-08-07T05:04:40.606759Z","iopub.status.idle":"2022-08-07T05:04:40.612614Z","shell.execute_reply":"2022-08-07T05:04:40.611639Z","shell.execute_reply.started":"2022-08-07T05:04:40.607052Z"},"trusted":true},"outputs":[],"source":["import os\n","import random\n","import torch\n","import torchvision\n","from torch.utils.data import random_split\n","import torchvision.models as models\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import copy\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Let us see the classes present in the dataset:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:40.615261Z","iopub.status.busy":"2022-08-07T05:04:40.614588Z","iopub.status.idle":"2022-08-07T05:04:40.626220Z","shell.execute_reply":"2022-08-07T05:04:40.625167Z","shell.execute_reply.started":"2022-08-07T05:04:40.615181Z"},"trusted":true},"outputs":[],"source":["# data_dir  = '/kaggle/input/garbage-classification/Garbage classification/Garbage classification'\n","data_dir  = 'fina_data'\n","classes = os.listdir(data_dir)\n","print(classes)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Transformations:"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Now, let's apply transformations to the dataset and import it for use."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Several data augmentations have been tried. The one with highest validation accuracy is kept"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:40.629333Z","iopub.status.busy":"2022-08-07T05:04:40.628673Z","iopub.status.idle":"2022-08-07T05:04:40.650235Z","shell.execute_reply":"2022-08-07T05:04:40.649506Z","shell.execute_reply.started":"2022-08-07T05:04:40.629295Z"},"trusted":true},"outputs":[],"source":["from torchvision.datasets import ImageFolder\n","import torchvision.transforms as transforms\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","import torch.nn.functional as F\n","\n","# Data augmentation and normalization for training\n","target_size = (224,224) # 256,256 for Resnet, 224,224 for mobilenet, 299,299 for inception\n","\n","transformations = transforms.Compose([\n","    #旋转\n","    transforms.RandomRotation(5),\n","    transforms.Resize(target_size),\n","    transforms.ColorJitter(brightness=0.2, contrast=0.1),\n","    #transforms.Resize((256,341)), \n","    #transforms.RandomCrop(size = target_size),\n","    #transforms.RandomHorizontalFlip(),\n","    \n","    transforms.ToTensor(),\n","    #transforms.Normalize([0.6610, 0.6283, 0.5894], [0.2085, 0.2085, 0.2302]) # ImageNet prior\n","  ])\n","\n","dataset = ImageFolder(data_dir, transform = transformations)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Let's create a helper function to see the image and its corresponding label:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:40.654808Z","iopub.status.busy":"2022-08-07T05:04:40.654554Z","iopub.status.idle":"2022-08-07T05:04:40.664131Z","shell.execute_reply":"2022-08-07T05:04:40.663396Z","shell.execute_reply.started":"2022-08-07T05:04:40.654783Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","def show_sample(img, label):\n","    print(\"Label:\", dataset.classes[label], \"(Class No: \"+ str(label) + \")\")\n","    plt.imshow(img.permute(1, 2, 0))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:40.667983Z","iopub.status.busy":"2022-08-07T05:04:40.667695Z","iopub.status.idle":"2022-08-07T05:04:40.766404Z","shell.execute_reply":"2022-08-07T05:04:40.765389Z","shell.execute_reply.started":"2022-08-07T05:04:40.667958Z"},"trusted":true},"outputs":[],"source":["#original image example\n","dataset0 = ImageFolder(data_dir, transform = None)\n","img, label = dataset0[203]\n","img"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:40.768396Z","iopub.status.busy":"2022-08-07T05:04:40.768013Z","iopub.status.idle":"2022-08-07T05:04:40.936320Z","shell.execute_reply":"2022-08-07T05:04:40.935518Z","shell.execute_reply.started":"2022-08-07T05:04:40.768343Z"},"trusted":true},"outputs":[],"source":["# transformed image\n","img, label = dataset[203]\n","show_sample(img, label)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Loading and Splitting Data:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:40.938019Z","iopub.status.busy":"2022-08-07T05:04:40.937524Z","iopub.status.idle":"2022-08-07T05:04:40.943777Z","shell.execute_reply":"2022-08-07T05:04:40.942718Z","shell.execute_reply.started":"2022-08-07T05:04:40.937978Z"},"trusted":true},"outputs":[],"source":["random_seed = 3047\n","torch.manual_seed(random_seed)\n","random.seed(random_seed)\n","np.random.seed(0)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We'll split the dataset into training, validation and test sets:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(len(dataset))\n","ld=len(dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:40.946095Z","iopub.status.busy":"2022-08-07T05:04:40.945422Z","iopub.status.idle":"2022-08-07T05:04:40.957917Z","shell.execute_reply":"2022-08-07T05:04:40.956696Z","shell.execute_reply.started":"2022-08-07T05:04:40.946052Z"},"trusted":true},"outputs":[],"source":["train_ds, val_ds, test_ds = random_split(dataset, [int(ld*0.8), int(ld*0.15), ld-int(ld*0.8)-int(ld*0.15)])\n","\n","len(train_ds), len(val_ds), len(test_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:40.960384Z","iopub.status.busy":"2022-08-07T05:04:40.960084Z","iopub.status.idle":"2022-08-07T05:04:40.965942Z","shell.execute_reply":"2022-08-07T05:04:40.964703Z","shell.execute_reply.started":"2022-08-07T05:04:40.960347Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data.dataloader import DataLoader\n","batch_size = 8"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Now, we'll create training and validation dataloaders using `DataLoader`."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:40.972064Z","iopub.status.busy":"2022-08-07T05:04:40.971282Z","iopub.status.idle":"2022-08-07T05:04:40.981584Z","shell.execute_reply":"2022-08-07T05:04:40.980542Z","shell.execute_reply.started":"2022-08-07T05:04:40.971869Z"},"trusted":true},"outputs":[],"source":["train_dl = DataLoader(train_ds, batch_size, shuffle = True, num_workers = 2, pin_memory = True)\n","val_dl = DataLoader(val_ds, batch_size*2, num_workers = 2, pin_memory = True)\n","test_dl = DataLoader(test_ds, batch_size*2, num_workers = 2, pin_memory = True) "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["This is a helper function to visualize batches:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:40.986144Z","iopub.status.busy":"2022-08-07T05:04:40.985524Z","iopub.status.idle":"2022-08-07T05:04:40.993856Z","shell.execute_reply":"2022-08-07T05:04:40.992627Z","shell.execute_reply.started":"2022-08-07T05:04:40.986099Z"},"trusted":true},"outputs":[],"source":["from torchvision.utils import make_grid\n","\n","def show_batch(dl):\n","    for images, labels in dl:\n","        fig, ax = plt.subplots(figsize=(12, 6))\n","        ax.set_xticks([])\n","        ax.set_yticks([])\n","        ax.imshow(make_grid(images, nrow = 16).permute(1, 2, 0))\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:40.996043Z","iopub.status.busy":"2022-08-07T05:04:40.995381Z","iopub.status.idle":"2022-08-07T05:04:43.912134Z","shell.execute_reply":"2022-08-07T05:04:43.907550Z","shell.execute_reply.started":"2022-08-07T05:04:40.995995Z"},"trusted":true},"outputs":[],"source":["# show_batch(train_dl)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Model Base:"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Let's create the model base:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:43.916118Z","iopub.status.busy":"2022-08-07T05:04:43.915238Z","iopub.status.idle":"2022-08-07T05:04:43.942125Z","shell.execute_reply":"2022-08-07T05:04:43.938742Z","shell.execute_reply.started":"2022-08-07T05:04:43.916078Z"},"trusted":true},"outputs":[],"source":["def accuracy(outputs, labels):\n","    _, preds = torch.max(outputs, dim=1)\n","    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n","\n","class ImageClassificationBase(nn.Module):\n","    def training_step(self, batch):\n","        images, labels = batch \n","        out = self(images)                  # Generate predictions\n","        loss = F.cross_entropy(out, labels) # Calculate loss\n","        return loss\n","    \n","    def validation_step(self, batch):\n","        images, labels = batch \n","        out = self(images)                    # Generate predictions\n","        loss = F.cross_entropy(out, labels)   # Calculate loss\n","        acc = accuracy(out, labels)           # Calculate accuracy\n","        return {'val_loss': loss.detach(), 'val_acc': acc}\n","        \n","    def validation_epoch_end(self, outputs):\n","        batch_losses = [x['val_loss'] for x in outputs]\n","        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n","        batch_accs = [x['val_acc'] for x in outputs]\n","        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n","        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n","    \n","    def epoch_end(self, epoch, result):\n","        print(\"Epoch {}: train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n","            epoch+1, result['train_loss'], result['val_loss'], result['val_acc']))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We'll compare the performance of three models: ResNet50, MobileNet V2, Inception V3"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:43.946138Z","iopub.status.busy":"2022-08-07T05:04:43.944529Z","iopub.status.idle":"2022-08-07T05:04:43.960220Z","shell.execute_reply":"2022-08-07T05:04:43.958788Z","shell.execute_reply.started":"2022-08-07T05:04:43.946087Z"},"trusted":true},"outputs":[],"source":["\n","class ResNet(ImageClassificationBase):\n","    def __init__(self):\n","        super().__init__()\n","\n","        # Use a pretrained model\n","        base_model = models.resnet18(pretrained=True)\n","\n","        # Save the number of input features for the fc layer\n","        num_ftrs = base_model.fc.in_features\n","        \n","        # Remove the avgpool and fc layer from the base model\n","        self.features = nn.Sequential(*list(base_model.children())[:-2])\n","\n","        # Create a new layer to replace the fc layer\n","        self.fc = nn.Conv2d(num_ftrs, len(dataset.classes), kernel_size=3)\n","    \n","    def forward(self, xb):\n","        # Use the base model to compute the features\n","        x = self.features(xb)\n","        # Apply the final convolutional layer\n","        x = self.fc(x)\n","        # Use adaptive average pooling to have the same output size\n","        x = F.adaptive_avg_pool2d(x, (1, 1))\n","        return torch.sigmoid(x.view(xb.size(0), -1))\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Choose from the three models. ResNet generates highest accuracy."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:44.028938Z","iopub.status.busy":"2022-08-07T05:04:44.028468Z","iopub.status.idle":"2022-08-07T05:04:45.156429Z","shell.execute_reply":"2022-08-07T05:04:45.155530Z","shell.execute_reply.started":"2022-08-07T05:04:44.028901Z"},"trusted":true},"outputs":[],"source":["import eiffnetv2\n","model = eiffnetv2.efficientnetv2_s(num_classes=7)\n","print(model)\n"," "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Porting to GPU:"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["GPUs tend to perform faster calculations than CPU. Let's take this advantage and use GPU for computation:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:45.158305Z","iopub.status.busy":"2022-08-07T05:04:45.157835Z","iopub.status.idle":"2022-08-07T05:04:45.167934Z","shell.execute_reply":"2022-08-07T05:04:45.167154Z","shell.execute_reply.started":"2022-08-07T05:04:45.158267Z"},"trusted":true},"outputs":[],"source":["def get_default_device():\n","    \"\"\"Pick GPU if available, else CPU\"\"\"\n","    if torch.cuda.is_available():\n","        return torch.device('cuda')\n","    else:\n","        return torch.device('cpu')\n","    \n","def to_device(data, device):\n","    \"\"\"Move tensor(s) to chosen device\"\"\"\n","    if isinstance(data, (list,tuple)):\n","        return [to_device(x, device) for x in data]\n","    return data.to(device, non_blocking=True)\n","\n","class DeviceDataLoader():\n","    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n","    def __init__(self, dl, device):\n","        self.dl = dl\n","        self.device = device\n","        \n","    def __iter__(self):\n","        \"\"\"Yield a batch of data after moving it to device\"\"\"\n","        for b in self.dl: \n","            yield to_device(b, self.device)\n","\n","    def __len__(self):\n","        \"\"\"Number of batches\"\"\"\n","        return len(self.dl)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:45.170281Z","iopub.status.busy":"2022-08-07T05:04:45.169914Z","iopub.status.idle":"2022-08-07T05:04:45.180785Z","shell.execute_reply":"2022-08-07T05:04:45.179845Z","shell.execute_reply.started":"2022-08-07T05:04:45.170244Z"},"trusted":true},"outputs":[],"source":["device = get_default_device()\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2022-08-07T05:04:45.182828Z","iopub.status.busy":"2022-08-07T05:04:45.182388Z","iopub.status.idle":"2022-08-07T05:04:45.227984Z","shell.execute_reply":"2022-08-07T05:04:45.227138Z","shell.execute_reply.started":"2022-08-07T05:04:45.182791Z"},"trusted":true},"outputs":[],"source":["train_dl = DeviceDataLoader(train_dl, device)\n","val_dl = DeviceDataLoader(val_dl, device)\n","test_dl = DeviceDataLoader(test_dl, device)\n","to_device(model, device)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Training the Model:"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["This is the function for fitting the model."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:45.229933Z","iopub.status.busy":"2022-08-07T05:04:45.229380Z","iopub.status.idle":"2022-08-07T05:04:45.241301Z","shell.execute_reply":"2022-08-07T05:04:45.240493Z","shell.execute_reply.started":"2022-08-07T05:04:45.229893Z"},"trusted":true},"outputs":[],"source":["@torch.no_grad()\n","def evaluate(model, val_loader):\n","    model.eval()\n","    outputs = [model.validation_step(batch) for batch in val_loader]\n","    return model.validation_epoch_end(outputs)\n","\n","def fit(epochs, lr, model, train_loader, val_loader, optimizer):\n","    history = []\n","    best_val_loss = 10\n","    patient = 15\n","   \n","    for epoch in range(epochs):\n","        # Training Phase \n","        model.train()\n","        train_losses = []\n","        for batch in train_loader:\n","            loss = model.training_step(batch)\n","            train_losses.append(loss)\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","        # Validation phase\n","        result = evaluate(model, val_loader)\n","        result['train_loss'] = torch.stack(train_losses).mean().item()\n","        model.epoch_end(epoch, result)\n","        history.append(result)\n","        \n","        # Reduce LR\n","        scheduler.step(result['val_loss'])\n","        \n","        # Early stopping\n","        if result['val_loss']>= best_val_loss:\n","            trigger += 1\n","            print('Trigger time',trigger)\n","            if trigger > patient:\n","                return history, best_model\n","        else:\n","            best_val_loss = result['val_loss']\n","            best_model = copy.deepcopy(model)\n","            trigger = 0\n","    return history,best_model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:45.242764Z","iopub.status.busy":"2022-08-07T05:04:45.242498Z","iopub.status.idle":"2022-08-07T05:04:45.258937Z","shell.execute_reply":"2022-08-07T05:04:45.258222Z","shell.execute_reply.started":"2022-08-07T05:04:45.242738Z"},"trusted":true},"outputs":[],"source":["model = to_device(model, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:45.262410Z","iopub.status.busy":"2022-08-07T05:04:45.262130Z","iopub.status.idle":"2022-08-07T05:04:45.273516Z","shell.execute_reply":"2022-08-07T05:04:45.272829Z","shell.execute_reply.started":"2022-08-07T05:04:45.262351Z"},"trusted":true},"outputs":[],"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","count_parameters(model)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Let's start training and fine-tuning the model:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:49:21.319369Z","iopub.status.busy":"2022-08-07T05:49:21.319043Z"},"trusted":true},"outputs":[],"source":["num_epochs = 90\n","lr = 5.5e-5\n","# optimizer = torch.optim.SGD(model.parameters(), \n","#                              lr = lr)\n","optimizer = torch.optim.Adam(model.parameters(), \n","                             #weight_decay = 1,\n","                             lr = lr)\n","scheduler = ReduceLROnPlateau(\n","    optimizer,\n","    factor = 0.9,\n","    patience=3,\n","    cooldown=0,\n","    min_lr=0,\n","    verbose=True\n",")\n","history,best_model = fit(num_epochs, lr, model, train_dl, val_dl, optimizer)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:48:41.647086Z","iopub.status.busy":"2022-08-07T05:48:41.646739Z","iopub.status.idle":"2022-08-07T05:48:43.966159Z","shell.execute_reply":"2022-08-07T05:48:43.965013Z","shell.execute_reply.started":"2022-08-07T05:48:41.647052Z"},"trusted":true},"outputs":[],"source":["evaluate(best_model, val_dl)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:49:01.354647Z","iopub.status.busy":"2022-08-07T05:49:01.354276Z","iopub.status.idle":"2022-08-07T05:49:09.254386Z","shell.execute_reply":"2022-08-07T05:49:09.253531Z","shell.execute_reply.started":"2022-08-07T05:49:01.354612Z"},"trusted":true},"outputs":[],"source":["evaluate(best_model, test_dl)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:13:50.241370Z","iopub.status.busy":"2022-08-07T05:13:50.241017Z","iopub.status.idle":"2022-08-07T05:13:50.384495Z","shell.execute_reply":"2022-08-07T05:13:50.383784Z","shell.execute_reply.started":"2022-08-07T05:13:50.241331Z"},"trusted":true},"outputs":[],"source":["def plot_accuracies(history):\n","    accuracies = [x['val_acc'] for x in history]\n","    plt.plot(accuracies, '-x')\n","    plt.xlabel('epoch')\n","    plt.ylabel('accuracy')\n","    plt.title('Accuracy vs. No. of epochs');\n","\n","plot_accuracies(history)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:13:50.386858Z","iopub.status.busy":"2022-08-07T05:13:50.386323Z","iopub.status.idle":"2022-08-07T05:13:50.541450Z","shell.execute_reply":"2022-08-07T05:13:50.540424Z","shell.execute_reply.started":"2022-08-07T05:13:50.386817Z"},"trusted":true},"outputs":[],"source":["def plot_losses(history):\n","    train_losses = [x.get('train_loss') for x in history]\n","    val_losses = [x['val_loss'] for x in history]\n","    plt.plot(train_losses, '-bx')\n","    plt.plot(val_losses, '-rx')\n","    plt.xlabel('epoch')\n","    plt.ylabel('loss')\n","    plt.legend(['Training', 'Validation'])\n","    plt.title('Loss vs. No. of epochs');\n","\n","plot_losses(history)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["****ROC, Sensitivity and Specificity****"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Plot multi class ROC for test data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:13:50.543091Z","iopub.status.busy":"2022-08-07T05:13:50.542747Z","iopub.status.idle":"2022-08-07T05:13:58.177635Z","shell.execute_reply":"2022-08-07T05:13:58.176535Z","shell.execute_reply.started":"2022-08-07T05:13:50.543061Z"},"trusted":true},"outputs":[],"source":["preds = torch.zeros((0,7)).cuda()\n","labels = torch.zeros((0)).cuda()\n","best_model.eval()\n","with torch.no_grad():\n","    for i, (images, label) in enumerate(test_dl):\n","        pred = best_model(images)\n","        preds = torch.cat((preds,pred),dim = 0)\n","        labels = torch.cat((labels,label.float()))\n","\n","# one hot encoding test labels\n","y_true = np.zeros(preds.shape)\n","for i in range (preds.shape[0]):\n","    for j in range(preds.shape[1]):\n","        y_true[i][j] = 1 if labels[i]== j else 0"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:13:58.180162Z","iopub.status.busy":"2022-08-07T05:13:58.179878Z","iopub.status.idle":"2022-08-07T05:13:58.859404Z","shell.execute_reply":"2022-08-07T05:13:58.858651Z","shell.execute_reply.started":"2022-08-07T05:13:58.180132Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from itertools import cycle\n","\n","from sklearn import svm, datasets\n","from sklearn.metrics import roc_curve, auc\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import label_binarize\n","from sklearn.multiclass import OneVsRestClassifier\n","from sklearn.metrics import roc_auc_score\n","fpr = dict()\n","tpr = dict()\n","roc_auc = dict()\n","n_classes = preds.shape[1]\n","out = preds.cpu().detach().numpy()\n","for i in range(n_classes):\n","    fpr[i], tpr[i], _ = roc_curve(y_true[:, i], out[:, i])\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","# Compute micro-average ROC curve and ROC area\n","fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true.ravel(), out.ravel())\n","roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:13:58.861079Z","iopub.status.busy":"2022-08-07T05:13:58.860738Z","iopub.status.idle":"2022-08-07T05:13:59.056312Z","shell.execute_reply":"2022-08-07T05:13:59.055489Z","shell.execute_reply.started":"2022-08-07T05:13:58.861036Z"},"trusted":true},"outputs":[],"source":["# First aggregate all false positive rates\n","all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n","\n","# Then interpolate all ROC curves at this points\n","mean_tpr = np.zeros_like(all_fpr)\n","for i in range(n_classes):\n","    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n","\n","# Finally average it and compute AUC\n","mean_tpr /= n_classes\n","\n","fpr[\"macro\"] = all_fpr\n","tpr[\"macro\"] = mean_tpr\n","roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n","\n","# Plot all ROC curves\n","plt.figure()\n","plt.plot(\n","    fpr[\"micro\"],\n","    tpr[\"micro\"],\n","    label=\"micro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n","    color=\"deeppink\",\n","    linestyle=\":\",\n","    linewidth=4,\n",")\n","\n","plt.plot(\n","    fpr[\"macro\"],\n","    tpr[\"macro\"],\n","    label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n","    color=\"navy\",\n","    linestyle=\":\",\n","    linewidth=4,\n",")\n","\n","colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n","for i, color in zip(range(n_classes), colors):\n","    plt.plot(\n","        fpr[i],\n","        tpr[i],\n","        color=color,\n","        lw=2,\n","        label=\"ROC curve of class {0} (area = {1:0.2f})\".format(dataset.classes[i], roc_auc[i]),\n","    )\n","\n","plt.plot([0, 1], [0, 1], \"k--\", lw=2)\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.title(\"ROC of multiclass prediction\")\n","plt.legend(loc=\"lower right\")\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Calculate sensitivity and specificity for each class"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:13:59.058340Z","iopub.status.busy":"2022-08-07T05:13:59.057760Z","iopub.status.idle":"2022-08-07T05:13:59.063550Z","shell.execute_reply":"2022-08-07T05:13:59.062772Z","shell.execute_reply.started":"2022-08-07T05:13:59.058299Z"},"trusted":true},"outputs":[],"source":["_, y_pred = torch.max(preds, dim=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:13:59.065772Z","iopub.status.busy":"2022-08-07T05:13:59.065181Z","iopub.status.idle":"2022-08-07T05:13:59.086077Z","shell.execute_reply":"2022-08-07T05:13:59.085173Z","shell.execute_reply.started":"2022-08-07T05:13:59.065733Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import classification_report\n","target_names = [dataset.classes[i] for i in range(7)]\n","print(classification_report(labels.cpu(), y_pred.cpu(), target_names = target_names))\n","print('Note: In binary classification, recall of the positive class is also known as “sensitivity”; \\n\\\n","recall of the negative class is “specificity”.')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Visualizing Predictions:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:13:59.087986Z","iopub.status.busy":"2022-08-07T05:13:59.087425Z","iopub.status.idle":"2022-08-07T05:13:59.093891Z","shell.execute_reply":"2022-08-07T05:13:59.093210Z","shell.execute_reply.started":"2022-08-07T05:13:59.087946Z"},"trusted":true},"outputs":[],"source":["def predict_image(img, model):\n","    # Convert to a batch of 1\n","    xb = to_device(img.unsqueeze(0), device)\n","    # Get predictions from model\n","    yb = model(xb)\n","    # Pick index with highest probability\n","    prob, preds  = torch.max(yb, dim=1)\n","    # Retrieve the class label\n","    return dataset.classes[preds[0].item()]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Let us see the model's predictions on the test dataset:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:13:59.096013Z","iopub.status.busy":"2022-08-07T05:13:59.095669Z","iopub.status.idle":"2022-08-07T05:13:59.295120Z","shell.execute_reply":"2022-08-07T05:13:59.294206Z","shell.execute_reply.started":"2022-08-07T05:13:59.095978Z"},"trusted":true},"outputs":[],"source":["img, label = test_ds[7]\n","plt.imshow(img.permute(1, 2, 0))\n","print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:13:59.297003Z","iopub.status.busy":"2022-08-07T05:13:59.296406Z","iopub.status.idle":"2022-08-07T05:13:59.481687Z","shell.execute_reply":"2022-08-07T05:13:59.480649Z","shell.execute_reply.started":"2022-08-07T05:13:59.296959Z"},"trusted":true},"outputs":[],"source":["img, label = test_ds[3]\n","plt.imshow(img.permute(1, 2, 0))\n","print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:13:59.483738Z","iopub.status.busy":"2022-08-07T05:13:59.483127Z","iopub.status.idle":"2022-08-07T05:13:59.668584Z","shell.execute_reply":"2022-08-07T05:13:59.667510Z","shell.execute_reply.started":"2022-08-07T05:13:59.483698Z"},"trusted":true},"outputs":[],"source":["img, label = test_ds[1]\n","plt.imshow(img.permute(1, 2, 0))\n","print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Conclusion:\n","\n","Our model is able to classify garbage with **95% accuracy**!\n","\n","It's great to see the model's predictions on the test set. It works pretty good on external images too!\n","\n","You can try experimenting with more images and see the results!"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### If you liked the kernel, don't forget to show some appreciation :)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## save model \n","import torch\n","\n","# state_dict = model.state_dict()\n","# torch.save(state_dict, checkpoint_new_file, _use_new_zipfile_serialization=False)\n","\n","torch.save(model.state_dict(), 'mobilenet_fcn.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","import torchvision\n","## load model and inference\n","model =MobileNet()\n","model_path  = 'mobilenet_fcn.pt' \n","model.load_state_dict(torch.load(model_path))\n","model=model.cuda()\n","model.eval()\n","\n","def img_preprocess(img):\n","    img = transformations(img)\n","    # img = img.unsqueeze(0)\n","    return img\n","\n","from PIL import Image\n","img = Image.open(r'data\\blue_tan\\img2.jpg')\n","img = img_preprocess(img)\n","predict_image(img, model)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","\n","  # 实例化您的PyTorch模型\n","# model.load_state_dict(torch.load('new_resnet18.pt'))\n","# model.eval()\n","size = (1,3,224,224)\n","dummy_input = torch.randn(*size).cuda()  # 替换为适当的输入形状\n","torch.onnx.export(model, dummy_input, model_path[:-3]+\".onnx\", verbose=True,opset_version=12)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def show_outputs(output):\n","    output_sorted = sorted(output, reverse=True)\n","    top5_str = '\\n-----TOP 5-----\\n'\n","    for i in range(5):\n","        value = output_sorted[i]\n","        index = np.where(output == value)\n","        for j in range(len(index)):\n","            if (i + j) >= 5:\n","                break\n","            if value > 0:\n","                topi = '{}: {}\\n'.format(index[j], value)\n","            else:\n","                topi = '-1: 0.0\\n'\n","            top5_str += topi\n","    print(top5_str)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":4}
