{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":[" \n"," "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Let us start by importing the libraries:"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2022-08-07T05:04:40.607083Z","iopub.status.busy":"2022-08-07T05:04:40.606759Z","iopub.status.idle":"2022-08-07T05:04:40.612614Z","shell.execute_reply":"2022-08-07T05:04:40.611639Z","shell.execute_reply.started":"2022-08-07T05:04:40.607052Z"},"trusted":true},"outputs":[],"source":["import os\n","import random\n","import torch\n","import torchvision\n","from torch.utils.data import random_split\n","import torchvision.models as models\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np\n","import copy\n","import   gc\n","\n","gc.collect()\n","torch.cuda.empty_cache()\n","! PYTORCH_CUDA_ALLOC_CONF=garbage_collection_threshold:0.95,max_split_size_mb:512"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Let us see the classes present in the dataset:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:40.615261Z","iopub.status.busy":"2022-08-07T05:04:40.614588Z","iopub.status.idle":"2022-08-07T05:04:40.626220Z","shell.execute_reply":"2022-08-07T05:04:40.625167Z","shell.execute_reply.started":"2022-08-07T05:04:40.615181Z"},"trusted":true},"outputs":[],"source":["# data_dir  = '/kaggle/input/garbage-classification/Garbage classification/Garbage classification'\n","data_dir  = 'fina_data'\n","classes = os.listdir(data_dir)\n","print(classes)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Transformations:"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Now, let's apply transformations to the dataset and import it for use."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Several data augmentations have been tried. The one with highest validation accuracy is kept"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:40.629333Z","iopub.status.busy":"2022-08-07T05:04:40.628673Z","iopub.status.idle":"2022-08-07T05:04:40.650235Z","shell.execute_reply":"2022-08-07T05:04:40.649506Z","shell.execute_reply.started":"2022-08-07T05:04:40.629295Z"},"trusted":true},"outputs":[],"source":["from torchvision.datasets import ImageFolder\n","import torchvision.transforms as transforms\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","import torch.nn.functional as F\n","\n","# Data augmentation and normalization for training\n","target_size = (224,224) # 256,256 for Resnet, 224,224 for mobilenet, 299,299 for inception\n","\n","transformations = transforms.Compose([\n","    #旋转\n","    transforms.RandomRotation(5),\n","    transforms.Resize(target_size),\n","    transforms.ColorJitter(brightness=0.2, contrast=0.1),\n","    #transforms.Resize((256,341)), \n","    #transforms.RandomCrop(size = target_size),\n","    #transforms.RandomHorizontalFlip(),\n","    \n","    transforms.ToTensor(),\n","    #transforms.Normalize([0.6610, 0.6283, 0.5894], [0.2085, 0.2085, 0.2302]) # ImageNet prior\n","  ])\n","\n","dataset = ImageFolder(data_dir, transform = transformations)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Let's create a helper function to see the image and its corresponding label:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:40.654808Z","iopub.status.busy":"2022-08-07T05:04:40.654554Z","iopub.status.idle":"2022-08-07T05:04:40.664131Z","shell.execute_reply":"2022-08-07T05:04:40.663396Z","shell.execute_reply.started":"2022-08-07T05:04:40.654783Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","def show_sample(img, label):\n","    print(\"Label:\", dataset.classes[label], \"(Class No: \"+ str(label) + \")\")\n","    plt.imshow(img.permute(1, 2, 0))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:40.667983Z","iopub.status.busy":"2022-08-07T05:04:40.667695Z","iopub.status.idle":"2022-08-07T05:04:40.766404Z","shell.execute_reply":"2022-08-07T05:04:40.765389Z","shell.execute_reply.started":"2022-08-07T05:04:40.667958Z"},"trusted":true},"outputs":[],"source":["#original image example\n","dataset0 = ImageFolder(data_dir, transform = None)\n","img, label = dataset0[203]\n","img"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:40.768396Z","iopub.status.busy":"2022-08-07T05:04:40.768013Z","iopub.status.idle":"2022-08-07T05:04:40.936320Z","shell.execute_reply":"2022-08-07T05:04:40.935518Z","shell.execute_reply.started":"2022-08-07T05:04:40.768343Z"},"trusted":true},"outputs":[],"source":["# transformed image\n","img, label = dataset[203]\n","show_sample(img, label)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Loading and Splitting Data:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:40.938019Z","iopub.status.busy":"2022-08-07T05:04:40.937524Z","iopub.status.idle":"2022-08-07T05:04:40.943777Z","shell.execute_reply":"2022-08-07T05:04:40.942718Z","shell.execute_reply.started":"2022-08-07T05:04:40.937978Z"},"trusted":true},"outputs":[],"source":["random_seed = 3407\n","torch.manual_seed(random_seed)\n","random.seed(random_seed)\n","np.random.seed(0)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We'll split the dataset into training, validation and test sets:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(len(dataset))\n","ld=len(dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:40.946095Z","iopub.status.busy":"2022-08-07T05:04:40.945422Z","iopub.status.idle":"2022-08-07T05:04:40.957917Z","shell.execute_reply":"2022-08-07T05:04:40.956696Z","shell.execute_reply.started":"2022-08-07T05:04:40.946052Z"},"trusted":true},"outputs":[],"source":["train_ds, val_ds, test_ds = random_split(dataset, [int(ld*0.8), int(ld*0.15), ld-int(ld*0.8)-int(ld*0.15)])\n","\n","len(train_ds), len(val_ds), len(test_ds)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:40.960384Z","iopub.status.busy":"2022-08-07T05:04:40.960084Z","iopub.status.idle":"2022-08-07T05:04:40.965942Z","shell.execute_reply":"2022-08-07T05:04:40.964703Z","shell.execute_reply.started":"2022-08-07T05:04:40.960347Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data.dataloader import DataLoader\n","batch_size = 16"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Now, we'll create training and validation dataloaders using `DataLoader`."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:40.972064Z","iopub.status.busy":"2022-08-07T05:04:40.971282Z","iopub.status.idle":"2022-08-07T05:04:40.981584Z","shell.execute_reply":"2022-08-07T05:04:40.980542Z","shell.execute_reply.started":"2022-08-07T05:04:40.971869Z"},"trusted":true},"outputs":[],"source":["train_dl = DataLoader(train_ds, batch_size, shuffle = True, num_workers = 2, pin_memory = True)\n","val_dl = DataLoader(val_ds, batch_size*2, num_workers = 2, pin_memory = True)\n","test_dl = DataLoader(test_ds, batch_size*2, num_workers = 2, pin_memory = True) "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["This is a helper function to visualize batches:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:40.986144Z","iopub.status.busy":"2022-08-07T05:04:40.985524Z","iopub.status.idle":"2022-08-07T05:04:40.993856Z","shell.execute_reply":"2022-08-07T05:04:40.992627Z","shell.execute_reply.started":"2022-08-07T05:04:40.986099Z"},"trusted":true},"outputs":[],"source":["from torchvision.utils import make_grid\n","\n","def show_batch(dl):\n","    for images, labels in dl:\n","        fig, ax = plt.subplots(figsize=(12, 6))\n","        ax.set_xticks([])\n","        ax.set_yticks([])\n","        ax.imshow(make_grid(images, nrow = 16).permute(1, 2, 0))\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:40.996043Z","iopub.status.busy":"2022-08-07T05:04:40.995381Z","iopub.status.idle":"2022-08-07T05:04:43.912134Z","shell.execute_reply":"2022-08-07T05:04:43.907550Z","shell.execute_reply.started":"2022-08-07T05:04:40.995995Z"},"trusted":true},"outputs":[],"source":["# show_batch(train_dl)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Model Base:"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Let's create the model base:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:43.916118Z","iopub.status.busy":"2022-08-07T05:04:43.915238Z","iopub.status.idle":"2022-08-07T05:04:43.942125Z","shell.execute_reply":"2022-08-07T05:04:43.938742Z","shell.execute_reply.started":"2022-08-07T05:04:43.916078Z"},"trusted":true},"outputs":[],"source":["def accuracy(outputs, labels):\n","    _, preds = torch.max(outputs, dim=1)\n","    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n","\n","class ImageClassificationBase(nn.Module):\n","    def training_step(self, batch):\n","        images, labels = batch \n","        out = self(images)                  # Generate predictions\n","        loss = F.cross_entropy(out, labels) # Calculate loss\n","        return loss\n","    \n","    def validation_step(self, batch):\n","        images, labels = batch \n","        out = self(images)                    # Generate predictions\n","        loss = F.cross_entropy(out, labels)   # Calculate loss\n","        acc = accuracy(out, labels)           # Calculate accuracy\n","        return {'val_loss': loss.detach(), 'val_acc': acc}\n","        \n","    def validation_epoch_end(self, outputs):\n","        batch_losses = [x['val_loss'] for x in outputs]\n","        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n","        batch_accs = [x['val_acc'] for x in outputs]\n","        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n","        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n","    \n","    def epoch_end(self, epoch, result):\n","        print(\"Epoch {}: train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n","            epoch+1, result['train_loss'], result['val_loss'], result['val_acc']))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We'll compare the performance of three models: ResNet50, MobileNet V2, Inception V3"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:43.946138Z","iopub.status.busy":"2022-08-07T05:04:43.944529Z","iopub.status.idle":"2022-08-07T05:04:43.960220Z","shell.execute_reply":"2022-08-07T05:04:43.958788Z","shell.execute_reply.started":"2022-08-07T05:04:43.946087Z"},"trusted":true},"outputs":[],"source":["# class ResNet(ImageClassificationBase):\n","#     def __init__(self):\n","#         super().__init__()\n","#        # Use a pretrained model\n","#         self.network = models.resnet18(pretrained=True)\n","#        # freeze the previous layers\n","# #         for param in self.network.parameters():\n","# #             param.requires_grad = False\n","#         # Replace last layer\n","#         num_ftrs = self.network.fc.in_features\n","#         self.network.fc = nn.Linear(num_ftrs, len(dataset.classes))\n","    \n","#     def forward(self, xb):\n","#         return torch.sigmoid(self.network(xb))\n","    \n","class ResNet(ImageClassificationBase):\n","    def __init__(self):\n","        super().__init__()\n","\n","        # Use a pretrained model\n","        base_model = models.resnet18(pretrained=True)\n","\n","        # Save the number of input features for the fc layer\n","        num_ftrs = base_model.fc.in_features\n","        \n","        # Remove the avgpool and fc layer from the base model\n","        self.features = nn.Sequential(*list(base_model.children())[:-2])\n","\n","        # Create a new layer to replace the fc layer\n","        self.fc1 = nn.Conv2d(num_ftrs, len(dataset.classes) , kernel_size=3) \n","    \n","    def forward(self, xb):\n","        # Use the base model to compute the features\n","        x = self.features(xb)\n","        # Apply the final convolutional layer\n","        # x = nn.ReLU()(x)\n","        x = self.fc1(x)\n","        \n","        # x = self.fc2(x)\n","        # Use adaptive average pooling to have the same output size\n","        x = F.adaptive_avg_pool2d(x, (1, 1))\n","        return  torch.sigmoid(x.view(xb.size(0), -1))#x.view(xb.size(0), -1) #\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:43.962468Z","iopub.status.busy":"2022-08-07T05:04:43.962071Z","iopub.status.idle":"2022-08-07T05:04:43.987852Z","shell.execute_reply":"2022-08-07T05:04:43.986720Z","shell.execute_reply.started":"2022-08-07T05:04:43.962429Z"},"trusted":true},"outputs":[],"source":["# class MobileNet(ImageClassificationBase):\n","#     def __init__(self, num_classes= len(dataset.classes)):\n","#         super().__init__()\n","#         # Load pretrained MobileNetV2 model\n","#         self.network = models.mobilenet_v2(pretrained=True)\n","\n","#         # # Freeze model parameters\n","#         # for param in self.network.parameters():\n","#         #     param.requires_grad = False\n","\n","#         # Get the number of output features for the feature extractor\n","#         out_features = self.network.classifier[1].in_features\n","\n","#         # Replace the classifier with a new one\n","#         self.network.classifier[1] = nn.Linear(out_features, num_classes)\n","\n","#     def forward(self, xb):\n","#         return self.network(xb)\n","class MobileNet(ImageClassificationBase):\n","    def __init__(self, num_classes= len(dataset.classes)):\n","        super().__init__()\n","        # Load pretrained MobileNetV2 model\n","        base_model = models.mobilenet_v2(pretrained=True)\n","\n","        # Freeze model parameters\n","        # for param in base_model.parameters():\n","        #     param.requires_grad = False\n","\n","        # The number of output features for the feature extractor\n","        out_features = 1280  # It's a fixed number in MobileNetV2\n","\n","        # Modify the last layer\n","        base_model.classifier = nn.Conv2d(out_features, num_classes, kernel_size=3)\n","\n","        self.features = base_model.features\n","        print(self.features)\n","        self.classifier = base_model.classifier\n","      \n","    def forward(self, xb):\n","        # Use the base model to compute the features\n","        x = self.features(xb)\n","        # Apply the final convolutional layer\n","        x = self.classifier(x)\n","        # Use global average pooling to have the same output size\n","        x = F.adaptive_avg_pool2d(x, (1, 1))\n","        return torch.sigmoid(x.view(xb.size(0), -1),1)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:43.990122Z","iopub.status.busy":"2022-08-07T05:04:43.989496Z","iopub.status.idle":"2022-08-07T05:04:44.008109Z","shell.execute_reply":"2022-08-07T05:04:44.006901Z","shell.execute_reply.started":"2022-08-07T05:04:43.990077Z"},"trusted":true},"outputs":[],"source":["class DenseNet(ImageClassificationBase):\n","    def __init__(self):\n","        super().__init__()\n","        self.network = torchvision.models.densenet121(pretrained=True)\n","        for param in self.network.parameters():\n","            param.requires_grad = False\n","        num_ftrs = self.network.classifier.in_features\n","        self.network.classifier = nn.Linear(num_ftrs, len(dataset.classes))\n","    def forward(self, xb):\n","        return torch.sigmoid(self.network(xb))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:44.016688Z","iopub.status.busy":"2022-08-07T05:04:44.012635Z","iopub.status.idle":"2022-08-07T05:04:44.026358Z","shell.execute_reply":"2022-08-07T05:04:44.023853Z","shell.execute_reply.started":"2022-08-07T05:04:44.016641Z"},"trusted":true},"outputs":[],"source":["class Inception(ImageClassificationBase):\n","    def __init__(self):\n","        super().__init__()\n","        self.network = torchvision.models.inception_v3(pretrained=True)\n","        self.network.aux_logits = False\n","        # for param in self.network.parameters():\n","        #   param.requires_grad = False\n","        # Parameters of newly constructed modules have requires_grad=True by default\n","        num_ftrs =  self.network.fc.in_features\n","        self.network.fc = nn.Linear(num_ftrs, len(dataset.classes))\n","    def forward(self, xb):\n","          return torch.sigmoid(self.network(xb),1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class LeNet(ImageClassificationBase):\n","    def __init__(self):\n","        super(LeNet, self).__init__()\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(3, 16, 3), # in_channels, out_channels, kernel_size\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2), # kernel_size, stride\n","            nn.Conv2d(16, 32,3),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2)\n","            # nn.Conv2d(32, 32,3),\n","            # nn.ReLU(),\n","            # nn.MaxPool2d(2, 2)\n","        )\n","        self.fc = nn.Sequential(\n","            nn.Linear( 32*52* 52*32, 128),\n","            nn.Sigmoid(),\n","            nn.Linear(128, 5),\n","            nn.Sigmoid()\n","        )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def Conv3x3BNReLU(in_channels,out_channels,stride=1,dilated=1):\n","    return nn.Sequential(\n","        nn.Conv2d(in_channels=in_channels,out_channels=out_channels,\n","                  kernel_size=3,stride=stride,padding=dilated,dilation=dilated,bias=False),\n","        nn.BatchNorm2d(out_channels),\n","        nn.ReLU6(inplace=True)\n","    )\n","\n","def Conv1x1BNReLU(in_channels,out_channels):\n","    return nn.Sequential(\n","        nn.Conv2d(in_channels=in_channels,out_channels=out_channels,\n","                  kernel_size=1,stride=1,padding=0,bias=False),\n","        nn.BatchNorm2d(out_channels),\n","        nn.ReLU6(inplace=True)\n","    )\n","\n","class Residual(nn.Module):\n","    def __init__(self, nchannels,dilated=1):\n","        super(Residual, self).__init__()\n","        mid_channels = nchannels // 2\n","        self.conv1x1 = Conv1x1BNReLU(in_channels=nchannels, out_channels=mid_channels)\n","        self.conv3x3 = Conv3x3BNReLU(in_channels=mid_channels, out_channels=nchannels,dilated=dilated)\n","\n","    def forward(self, x):\n","        out = self.conv3x3(self.conv1x1(x))\n","        return out + x\n","\n","class Darknet53(ImageClassificationBase):\n","    def __init__(self, num_classes=len(dataset.classes)):\n","        super(Darknet53, self).__init__()\n","        self.first_conv = Conv3x3BNReLU(in_channels=3, out_channels=32)\n","        self.block1 = self._make_layers(in_channels=32,out_channels=64, block_num=1,stride=2)\n","        self.block2 = self._make_layers(in_channels=64,out_channels=128, block_num=2,stride=2)\n","        self.block3 = self._make_layers(in_channels=128,out_channels=256, block_num=8,stride=2)\n","        self.block4 = self._make_layers(in_channels=256,out_channels=512, block_num=8,stride=1,dilated=2)\n","        self.block5 = self._make_layers(in_channels=512,out_channels=1024, block_num=4,stride=1,dilated=4)\n","\n","        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n","        self.linear = nn.Linear(in_features=1024,out_features=num_classes)\n","        self.softmax = nn.Softmax(dim=1)\n","\n","    def _make_layers(self, in_channels,out_channels, block_num,dilated=1,stride=1):\n","        _layers = []\n","        _layers.append(Conv3x3BNReLU(in_channels=in_channels, out_channels=out_channels, stride=stride,dilated=dilated))\n","        for _ in range(block_num):\n","            _layers.append(Residual(nchannels=out_channels,dilated=dilated))\n","        return nn.Sequential(*_layers)\n","\n","    def forward(self, x):\n","        x = self.first_conv(x)\n","        x = self.block1(x)\n","        x = self.block2(x)\n","        x = self.block3(x) # 1 256 32 32\n","        x = self.block4(x)\n","        x = self.block5(x)\n","\n","        x = self.avg_pool(x)\n","        x = x.view(x.size(0),-1)\n","        x = self.linear(x)\n","        out = self.softmax(x)\n","        return out "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Choose from the three models. ResNet generates highest accuracy."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:44.028938Z","iopub.status.busy":"2022-08-07T05:04:44.028468Z","iopub.status.idle":"2022-08-07T05:04:45.156429Z","shell.execute_reply":"2022-08-07T05:04:45.155530Z","shell.execute_reply.started":"2022-08-07T05:04:44.028901Z"},"trusted":true},"outputs":[],"source":["model =ResNet()\n","print(model)\n","# model = le_net()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Porting to GPU:"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["GPUs tend to perform faster calculations than CPU. Let's take this advantage and use GPU for computation:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:45.158305Z","iopub.status.busy":"2022-08-07T05:04:45.157835Z","iopub.status.idle":"2022-08-07T05:04:45.167934Z","shell.execute_reply":"2022-08-07T05:04:45.167154Z","shell.execute_reply.started":"2022-08-07T05:04:45.158267Z"},"trusted":true},"outputs":[],"source":["def get_default_device():\n","    \"\"\"Pick GPU if available, else CPU\"\"\"\n","    if torch.cuda.is_available():\n","        return torch.device('cuda')\n","    else:\n","        return torch.device('cpu')\n","    \n","def to_device(data, device):\n","    \"\"\"Move tensor(s) to chosen device\"\"\"\n","    if isinstance(data, (list,tuple)):\n","        return [to_device(x, device) for x in data]\n","    return data.to(device, non_blocking=True)\n","\n","class DeviceDataLoader():\n","    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n","    def __init__(self, dl, device):\n","        self.dl = dl\n","        self.device = device\n","        \n","    def __iter__(self):\n","        \"\"\"Yield a batch of data after moving it to device\"\"\"\n","        for b in self.dl: \n","            yield to_device(b, self.device)\n","\n","    def __len__(self):\n","        \"\"\"Number of batches\"\"\"\n","        return len(self.dl)\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:45.170281Z","iopub.status.busy":"2022-08-07T05:04:45.169914Z","iopub.status.idle":"2022-08-07T05:04:45.180785Z","shell.execute_reply":"2022-08-07T05:04:45.179845Z","shell.execute_reply.started":"2022-08-07T05:04:45.170244Z"},"trusted":true},"outputs":[],"source":["device = get_default_device()\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2022-08-07T05:04:45.182828Z","iopub.status.busy":"2022-08-07T05:04:45.182388Z","iopub.status.idle":"2022-08-07T05:04:45.227984Z","shell.execute_reply":"2022-08-07T05:04:45.227138Z","shell.execute_reply.started":"2022-08-07T05:04:45.182791Z"},"trusted":true},"outputs":[],"source":["train_dl = DeviceDataLoader(train_dl, device)\n","val_dl = DeviceDataLoader(val_dl, device)\n","test_dl = DeviceDataLoader(test_dl, device)\n","to_device(model, device)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Training the Model:"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["This is the function for fitting the model."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:45.229933Z","iopub.status.busy":"2022-08-07T05:04:45.229380Z","iopub.status.idle":"2022-08-07T05:04:45.241301Z","shell.execute_reply":"2022-08-07T05:04:45.240493Z","shell.execute_reply.started":"2022-08-07T05:04:45.229893Z"},"trusted":true},"outputs":[],"source":["@torch.no_grad()\n","def evaluate(model, val_loader):\n","    model.eval()\n","    outputs = [model.validation_step(batch) for batch in val_loader]\n","    return model.validation_epoch_end(outputs)\n","\n","def fit(epochs, lr, model, train_loader, val_loader, optimizer):\n","    history = []\n","    best_val_loss = 10\n","    patient = 15\n","   \n","    for epoch in range(epochs):\n","        # Training Phase \n","        model.train()\n","        train_losses = []\n","        for batch in train_loader:\n","            loss = model.training_step(batch)\n","            train_losses.append(loss)\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","        # Validation phase\n","        result = evaluate(model, val_loader)\n","        result['train_loss'] = torch.stack(train_losses).mean().item()\n","        model.epoch_end(epoch, result)\n","        history.append(result)\n","        \n","        # Reduce LR\n","        scheduler.step(result['val_loss'])\n","        \n","        # Early stopping\n","        if result['val_loss']>= best_val_loss:\n","            trigger += 1\n","            print('Trigger time',trigger)\n","            if trigger > patient:\n","                return history, best_model\n","        else:\n","            best_val_loss = result['val_loss']\n","            best_model = copy.deepcopy(model)\n","            trigger = 0\n","    return history,best_model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:45.242764Z","iopub.status.busy":"2022-08-07T05:04:45.242498Z","iopub.status.idle":"2022-08-07T05:04:45.258937Z","shell.execute_reply":"2022-08-07T05:04:45.258222Z","shell.execute_reply.started":"2022-08-07T05:04:45.242738Z"},"trusted":true},"outputs":[],"source":["model = to_device(model, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:04:45.262410Z","iopub.status.busy":"2022-08-07T05:04:45.262130Z","iopub.status.idle":"2022-08-07T05:04:45.273516Z","shell.execute_reply":"2022-08-07T05:04:45.272829Z","shell.execute_reply.started":"2022-08-07T05:04:45.262351Z"},"trusted":true},"outputs":[],"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","count_parameters(model)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Let's start training and fine-tuning the model:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:49:21.319369Z","iopub.status.busy":"2022-08-07T05:49:21.319043Z"},"trusted":true},"outputs":[],"source":["num_epochs = 90\n","lr = 5.5e-5\n","# optimizer = torch.optim.SGD(model.parameters(), \n","#                              lr = lr)\n","optimizer = torch.optim.Adam(model.parameters(), \n","                             #weight_decay = 1,\n","                             lr = lr)\n","scheduler = ReduceLROnPlateau(\n","    optimizer,\n","    factor = 0.9,\n","    patience=3,\n","    cooldown=0,\n","    min_lr=0,\n","    verbose=True\n",")\n","history,best_model = fit(num_epochs, lr, model, train_dl, val_dl, optimizer)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:48:41.647086Z","iopub.status.busy":"2022-08-07T05:48:41.646739Z","iopub.status.idle":"2022-08-07T05:48:43.966159Z","shell.execute_reply":"2022-08-07T05:48:43.965013Z","shell.execute_reply.started":"2022-08-07T05:48:41.647052Z"},"trusted":true},"outputs":[],"source":["evaluate(best_model, val_dl)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:49:01.354647Z","iopub.status.busy":"2022-08-07T05:49:01.354276Z","iopub.status.idle":"2022-08-07T05:49:09.254386Z","shell.execute_reply":"2022-08-07T05:49:09.253531Z","shell.execute_reply.started":"2022-08-07T05:49:01.354612Z"},"trusted":true},"outputs":[],"source":["evaluate(best_model, test_dl)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:13:50.241370Z","iopub.status.busy":"2022-08-07T05:13:50.241017Z","iopub.status.idle":"2022-08-07T05:13:50.384495Z","shell.execute_reply":"2022-08-07T05:13:50.383784Z","shell.execute_reply.started":"2022-08-07T05:13:50.241331Z"},"trusted":true},"outputs":[],"source":["def plot_accuracies(history):\n","    accuracies = [x['val_acc'] for x in history]\n","    plt.plot(accuracies, '-x')\n","    plt.xlabel('epoch')\n","    plt.ylabel('accuracy')\n","    plt.title('Accuracy vs. No. of epochs');\n","\n","plot_accuracies(history)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:13:50.386858Z","iopub.status.busy":"2022-08-07T05:13:50.386323Z","iopub.status.idle":"2022-08-07T05:13:50.541450Z","shell.execute_reply":"2022-08-07T05:13:50.540424Z","shell.execute_reply.started":"2022-08-07T05:13:50.386817Z"},"trusted":true},"outputs":[],"source":["def plot_losses(history):\n","    train_losses = [x.get('train_loss') for x in history]\n","    val_losses = [x['val_loss'] for x in history]\n","    plt.plot(train_losses, '-bx')\n","    plt.plot(val_losses, '-rx')\n","    plt.xlabel('epoch')\n","    plt.ylabel('loss')\n","    plt.legend(['Training', 'Validation'])\n","    plt.title('Loss vs. No. of epochs');\n","\n","plot_losses(history)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["****ROC, Sensitivity and Specificity****"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Plot multi class ROC for test data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:13:50.543091Z","iopub.status.busy":"2022-08-07T05:13:50.542747Z","iopub.status.idle":"2022-08-07T05:13:58.177635Z","shell.execute_reply":"2022-08-07T05:13:58.176535Z","shell.execute_reply.started":"2022-08-07T05:13:50.543061Z"},"trusted":true},"outputs":[],"source":["preds = torch.zeros((0,7)).cuda()\n","labels = torch.zeros((0)).cuda()\n","best_model.eval()\n","with torch.no_grad():\n","    for i, (images, label) in enumerate(test_dl):\n","        pred = best_model(images)\n","        preds = torch.cat((preds,pred),dim = 0)\n","        labels = torch.cat((labels,label.float()))\n","\n","# one hot encoding test labels\n","y_true = np.zeros(preds.shape)\n","for i in range (preds.shape[0]):\n","    for j in range(preds.shape[1]):\n","        y_true[i][j] = 1 if labels[i]== j else 0"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:13:58.180162Z","iopub.status.busy":"2022-08-07T05:13:58.179878Z","iopub.status.idle":"2022-08-07T05:13:58.859404Z","shell.execute_reply":"2022-08-07T05:13:58.858651Z","shell.execute_reply.started":"2022-08-07T05:13:58.180132Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from itertools import cycle\n","\n","from sklearn import svm, datasets\n","from sklearn.metrics import roc_curve, auc\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import label_binarize\n","from sklearn.multiclass import OneVsRestClassifier\n","from sklearn.metrics import roc_auc_score\n","fpr = dict()\n","tpr = dict()\n","roc_auc = dict()\n","n_classes = preds.shape[1]\n","out = preds.cpu().detach().numpy()\n","for i in range(n_classes):\n","    fpr[i], tpr[i], _ = roc_curve(y_true[:, i], out[:, i])\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","# Compute micro-average ROC curve and ROC area\n","fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_true.ravel(), out.ravel())\n","roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:13:58.861079Z","iopub.status.busy":"2022-08-07T05:13:58.860738Z","iopub.status.idle":"2022-08-07T05:13:59.056312Z","shell.execute_reply":"2022-08-07T05:13:59.055489Z","shell.execute_reply.started":"2022-08-07T05:13:58.861036Z"},"trusted":true},"outputs":[],"source":["# First aggregate all false positive rates\n","all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n","\n","# Then interpolate all ROC curves at this points\n","mean_tpr = np.zeros_like(all_fpr)\n","for i in range(n_classes):\n","    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n","\n","# Finally average it and compute AUC\n","mean_tpr /= n_classes\n","\n","fpr[\"macro\"] = all_fpr\n","tpr[\"macro\"] = mean_tpr\n","roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n","\n","# Plot all ROC curves\n","plt.figure()\n","plt.plot(\n","    fpr[\"micro\"],\n","    tpr[\"micro\"],\n","    label=\"micro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"micro\"]),\n","    color=\"deeppink\",\n","    linestyle=\":\",\n","    linewidth=4,\n",")\n","\n","plt.plot(\n","    fpr[\"macro\"],\n","    tpr[\"macro\"],\n","    label=\"macro-average ROC curve (area = {0:0.2f})\".format(roc_auc[\"macro\"]),\n","    color=\"navy\",\n","    linestyle=\":\",\n","    linewidth=4,\n",")\n","\n","colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n","for i, color in zip(range(n_classes), colors):\n","    plt.plot(\n","        fpr[i],\n","        tpr[i],\n","        color=color,\n","        lw=2,\n","        label=\"ROC curve of class {0} (area = {1:0.2f})\".format(dataset.classes[i], roc_auc[i]),\n","    )\n","\n","plt.plot([0, 1], [0, 1], \"k--\", lw=2)\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel(\"False Positive Rate\")\n","plt.ylabel(\"True Positive Rate\")\n","plt.title(\"ROC of multiclass prediction\")\n","plt.legend(loc=\"lower right\")\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Calculate sensitivity and specificity for each class"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:13:59.058340Z","iopub.status.busy":"2022-08-07T05:13:59.057760Z","iopub.status.idle":"2022-08-07T05:13:59.063550Z","shell.execute_reply":"2022-08-07T05:13:59.062772Z","shell.execute_reply.started":"2022-08-07T05:13:59.058299Z"},"trusted":true},"outputs":[],"source":["_, y_pred = torch.max(preds, dim=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:13:59.065772Z","iopub.status.busy":"2022-08-07T05:13:59.065181Z","iopub.status.idle":"2022-08-07T05:13:59.086077Z","shell.execute_reply":"2022-08-07T05:13:59.085173Z","shell.execute_reply.started":"2022-08-07T05:13:59.065733Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import classification_report\n","target_names = [dataset.classes[i] for i in range(7)]\n","print(classification_report(labels.cpu(), y_pred.cpu(), target_names = target_names))\n","print('Note: In binary classification, recall of the positive class is also known as “sensitivity”; \\n\\\n","recall of the negative class is “specificity”.')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Visualizing Predictions:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:13:59.087986Z","iopub.status.busy":"2022-08-07T05:13:59.087425Z","iopub.status.idle":"2022-08-07T05:13:59.093891Z","shell.execute_reply":"2022-08-07T05:13:59.093210Z","shell.execute_reply.started":"2022-08-07T05:13:59.087946Z"},"trusted":true},"outputs":[],"source":["def predict_image(img, model):\n","    # Convert to a batch of 1\n","    xb = to_device(img.unsqueeze(0), device)\n","    # Get predictions from model\n","    yb = model(xb)\n","    # Pick index with highest probability\n","    prob, preds  = torch.max(yb, dim=1)\n","    # Retrieve the class label\n","    return dataset.classes[preds[0].item()]"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Let us see the model's predictions on the test dataset:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:13:59.096013Z","iopub.status.busy":"2022-08-07T05:13:59.095669Z","iopub.status.idle":"2022-08-07T05:13:59.295120Z","shell.execute_reply":"2022-08-07T05:13:59.294206Z","shell.execute_reply.started":"2022-08-07T05:13:59.095978Z"},"trusted":true},"outputs":[],"source":["img, label = test_ds[7]\n","plt.imshow(img.permute(1, 2, 0))\n","print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:13:59.297003Z","iopub.status.busy":"2022-08-07T05:13:59.296406Z","iopub.status.idle":"2022-08-07T05:13:59.481687Z","shell.execute_reply":"2022-08-07T05:13:59.480649Z","shell.execute_reply.started":"2022-08-07T05:13:59.296959Z"},"trusted":true},"outputs":[],"source":["img, label = test_ds[3]\n","plt.imshow(img.permute(1, 2, 0))\n","print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-08-07T05:13:59.483738Z","iopub.status.busy":"2022-08-07T05:13:59.483127Z","iopub.status.idle":"2022-08-07T05:13:59.668584Z","shell.execute_reply":"2022-08-07T05:13:59.667510Z","shell.execute_reply.started":"2022-08-07T05:13:59.483698Z"},"trusted":true},"outputs":[],"source":["img, label = test_ds[1]\n","plt.imshow(img.permute(1, 2, 0))\n","print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Conclusion:\n","\n","Our model is able to classify garbage with **95% accuracy**!\n","\n","It's great to see the model's predictions on the test set. It works pretty good on external images too!\n","\n","You can try experimenting with more images and see the results!"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### If you liked the kernel, don't forget to show some appreciation :)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## save model \n","import torch\n","\n","# state_dict = model.state_dict()\n","# torch.save(state_dict, checkpoint_new_file, _use_new_zipfile_serialization=False)\n","\n","torch.save(model.state_dict(), 'ResNet_fcn.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","import torchvision\n","## load model and inference\n","model =ResNet() \n","model_path  = 'ResNet_fcn.pt' \n","model.load_state_dict(torch.load(model_path))\n","model=model.cuda()\n","model.eval()\n","\n","def img_preprocess(img):\n","    img = transformations(img)\n","    # img = img.unsqueeze(0)\n","    return img\n","\n","from PIL import Image\n","img = Image.open(r'data\\blue_tan\\img2.jpg')\n","img = img_preprocess(img)\n","predict_image(img, model)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","\n","  # 实例化您的PyTorch模型\n","# model.load_state_dict(torch.load('new_resnet18.pt'))\n","# model.eval()\n","size = (1,3,224,224)\n","dummy_input = torch.randn(*size).cuda()  # 替换为适当的输入形状\n","torch.onnx.export(model, dummy_input, model_path[:-3]+\".onnx\", verbose=True,opset_version=12)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def show_outputs(output):\n","    output_sorted = sorted(output, reverse=True)\n","    top5_str = '\\n-----TOP 5-----\\n'\n","    for i in range(5):\n","        value = output_sorted[i]\n","        index = np.where(output == value)\n","        for j in range(len(index)):\n","            if (i + j) >= 5:\n","                break\n","            if value > 0:\n","                topi = '{}: {}\\n'.format(index[j], value)\n","            else:\n","                topi = '-1: 0.0\\n'\n","            top5_str += topi\n","    print(top5_str)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":4}
